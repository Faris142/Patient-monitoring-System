{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras_tuner\n",
      "  Using cached keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras_tuner) (3.3.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras_tuner) (24.0)\n",
      "Requirement already satisfied: requests in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras_tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras_tuner)\n",
      "  Using cached kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras->keras_tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras->keras_tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras->keras_tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras->keras_tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras->keras_tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras->keras_tuner) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras->keras_tuner) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->keras_tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->keras_tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->keras_tuner) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->keras_tuner) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from optree->keras->keras_tuner) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras->keras_tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras->keras_tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\faisa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
      "Using cached keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Using cached kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras_tuner\n",
      "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_shape = (128, 128, 3)  \n",
    "batch_size = 32\n",
    "num_classes = 6  \n",
    "epochs = 20\n",
    "\n",
    "base_path = './Classify'\n",
    "train_dir = os.path.join(base_path, 'train')\n",
    "test_dir = os.path.join(base_path, 'test')\n",
    "labels = ['backpain', 'chestpain', 'cough', 'falling_down', 'headache', 'neckpain']\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jpg\"):  \n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = load_img(img_path, target_size=(128, 128))\n",
    "            img_array = img_to_array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "def load_dataset(base_dir, labels):\n",
    "    data = []\n",
    "    label_list = []\n",
    "    for label in labels:\n",
    "        folder_path = os.path.join(base_dir, label)\n",
    "        if os.path.isdir(folder_path):\n",
    "            images, lbls = load_images_from_folder(folder_path, label)\n",
    "            data.extend(images)\n",
    "            label_list.extend(lbls)\n",
    "    data = np.array(data)\n",
    "    label_list = np.array(label_list)\n",
    "    return data, label_list\n",
    "\n",
    "train_data, train_labels = load_dataset(train_dir, labels)\n",
    "test_data, test_labels = load_dataset(test_dir, labels)\n",
    "\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "train_labels = np.array([label_to_index[label] for label in train_labels])\n",
    "test_labels = np.array([label_to_index[label] for label in test_labels])\n",
    "\n",
    "train_data = train_data.astype('float32') / 255.0\n",
    "test_data = test_data.astype('float32') / 255.0\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes)\n",
    "test_labels = to_categorical(test_labels, num_classes)\n",
    "\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faisa\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 110ms/step - accuracy: 0.2986 - loss: 1.8356 - val_accuracy: 0.3699 - val_loss: 1.6645\n",
      "Epoch 2/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.3749 - loss: 1.6583 - val_accuracy: 0.3699 - val_loss: 1.6617\n",
      "Epoch 3/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.4000 - loss: 1.6239 - val_accuracy: 0.3699 - val_loss: 1.6609\n",
      "Epoch 4/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.3905 - loss: 1.6281 - val_accuracy: 0.3618 - val_loss: 1.6687\n",
      "Epoch 5/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.3875 - loss: 1.6099 - val_accuracy: 0.3638 - val_loss: 1.6453\n",
      "Epoch 6/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.3974 - loss: 1.5890 - val_accuracy: 0.3577 - val_loss: 1.6316\n",
      "Epoch 7/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - accuracy: 0.3895 - loss: 1.5927 - val_accuracy: 0.3537 - val_loss: 1.6238\n",
      "Epoch 8/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.4125 - loss: 1.5492 - val_accuracy: 0.3740 - val_loss: 1.6180\n",
      "Epoch 9/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.4104 - loss: 1.4883 - val_accuracy: 0.3801 - val_loss: 1.5886\n",
      "Epoch 10/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.4371 - loss: 1.4245 - val_accuracy: 0.4329 - val_loss: 1.5567\n",
      "Epoch 11/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.4587 - loss: 1.3831 - val_accuracy: 0.4492 - val_loss: 1.5321\n",
      "Epoch 12/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.5068 - loss: 1.2624 - val_accuracy: 0.4512 - val_loss: 1.4997\n",
      "Epoch 13/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.5266 - loss: 1.2066 - val_accuracy: 0.4919 - val_loss: 1.4351\n",
      "Epoch 14/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.5869 - loss: 1.0721 - val_accuracy: 0.5000 - val_loss: 1.4267\n",
      "Epoch 15/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 106ms/step - accuracy: 0.6133 - loss: 0.9761 - val_accuracy: 0.4939 - val_loss: 1.4380\n",
      "Epoch 16/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.6480 - loss: 0.8973 - val_accuracy: 0.5386 - val_loss: 1.4176\n",
      "Epoch 17/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.6758 - loss: 0.8096 - val_accuracy: 0.5346 - val_loss: 1.4581\n",
      "Epoch 18/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.7337 - loss: 0.7209 - val_accuracy: 0.5528 - val_loss: 1.4479\n",
      "Epoch 19/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - accuracy: 0.7676 - loss: 0.6191 - val_accuracy: 0.5650 - val_loss: 1.4726\n",
      "Epoch 20/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.8065 - loss: 0.5423 - val_accuracy: 0.6199 - val_loss: 1.4740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x299ebbe3010>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_data, train_labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(val_data, val_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.3403 - loss: 1.8051 - val_accuracy: 0.3699 - val_loss: 1.6695\n",
      "Epoch 2/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.3596 - loss: 1.6773 - val_accuracy: 0.3699 - val_loss: 1.6666\n",
      "Epoch 3/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - accuracy: 0.3935 - loss: 1.6327 - val_accuracy: 0.3618 - val_loss: 1.6737\n",
      "Epoch 4/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - accuracy: 0.3818 - loss: 1.6284 - val_accuracy: 0.3679 - val_loss: 1.6601\n",
      "Epoch 5/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - accuracy: 0.3757 - loss: 1.6278 - val_accuracy: 0.3679 - val_loss: 1.6728\n",
      "Epoch 6/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - accuracy: 0.3880 - loss: 1.5911 - val_accuracy: 0.3618 - val_loss: 1.6507\n",
      "Epoch 7/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - accuracy: 0.3977 - loss: 1.5785 - val_accuracy: 0.3516 - val_loss: 1.6454\n",
      "Epoch 8/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - accuracy: 0.3644 - loss: 1.5683 - val_accuracy: 0.3577 - val_loss: 1.6316\n",
      "Epoch 9/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - accuracy: 0.3976 - loss: 1.5057 - val_accuracy: 0.3496 - val_loss: 1.6203\n",
      "Epoch 10/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - accuracy: 0.4244 - loss: 1.4524 - val_accuracy: 0.3780 - val_loss: 1.5805\n",
      "Epoch 11/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - accuracy: 0.4684 - loss: 1.3432 - val_accuracy: 0.4228 - val_loss: 1.5787\n",
      "Epoch 12/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - accuracy: 0.5150 - loss: 1.2487 - val_accuracy: 0.4431 - val_loss: 1.5177\n",
      "Epoch 13/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step - accuracy: 0.5460 - loss: 1.1851 - val_accuracy: 0.4715 - val_loss: 1.4680\n",
      "Epoch 14/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - accuracy: 0.6050 - loss: 1.0475 - val_accuracy: 0.4817 - val_loss: 1.5416\n",
      "Epoch 15/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.6125 - loss: 1.0013 - val_accuracy: 0.5122 - val_loss: 1.5196\n",
      "Epoch 16/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - accuracy: 0.6772 - loss: 0.8342 - val_accuracy: 0.5305 - val_loss: 1.4715\n",
      "Epoch 17/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - accuracy: 0.7022 - loss: 0.7781 - val_accuracy: 0.5630 - val_loss: 1.4855\n",
      "Epoch 18/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - accuracy: 0.7305 - loss: 0.7184 - val_accuracy: 0.5854 - val_loss: 1.6285\n",
      "Epoch 19/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - accuracy: 0.7690 - loss: 0.6051 - val_accuracy: 0.5752 - val_loss: 1.6028\n",
      "Epoch 20/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 109ms/step - accuracy: 0.7908 - loss: 0.5751 - val_accuracy: 0.5874 - val_loss: 1.6198\n",
      "Epoch 21/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.8141 - loss: 0.4960 - val_accuracy: 0.5996 - val_loss: 1.7225\n",
      "Epoch 22/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.8216 - loss: 0.4569 - val_accuracy: 0.5976 - val_loss: 1.7888\n",
      "Epoch 23/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.8478 - loss: 0.4162 - val_accuracy: 0.5935 - val_loss: 1.9988\n",
      "Epoch 24/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.8601 - loss: 0.3517 - val_accuracy: 0.6098 - val_loss: 1.9952\n",
      "Epoch 25/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.8759 - loss: 0.3279 - val_accuracy: 0.6138 - val_loss: 2.0799\n",
      "Epoch 26/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.8950 - loss: 0.2845 - val_accuracy: 0.6057 - val_loss: 2.1208\n",
      "Epoch 27/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.8807 - loss: 0.3116 - val_accuracy: 0.6402 - val_loss: 2.1232\n",
      "Epoch 28/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9062 - loss: 0.2556 - val_accuracy: 0.6280 - val_loss: 2.3101\n",
      "Epoch 29/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.9108 - loss: 0.2436 - val_accuracy: 0.6321 - val_loss: 2.4177\n",
      "Epoch 30/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9135 - loss: 0.2471 - val_accuracy: 0.6382 - val_loss: 1.8752\n",
      "Epoch 31/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.9223 - loss: 0.2284 - val_accuracy: 0.6341 - val_loss: 2.2768\n",
      "Epoch 32/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9321 - loss: 0.1938 - val_accuracy: 0.6382 - val_loss: 2.5851\n",
      "Epoch 33/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.9364 - loss: 0.1691 - val_accuracy: 0.6301 - val_loss: 2.3503\n",
      "Epoch 34/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9248 - loss: 0.2011 - val_accuracy: 0.6443 - val_loss: 2.0849\n",
      "Epoch 35/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9333 - loss: 0.1804 - val_accuracy: 0.6341 - val_loss: 2.2207\n",
      "Epoch 36/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9445 - loss: 0.1514 - val_accuracy: 0.6463 - val_loss: 2.3158\n",
      "Epoch 37/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.9447 - loss: 0.1499 - val_accuracy: 0.6179 - val_loss: 2.7652\n",
      "Epoch 38/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9380 - loss: 0.1604 - val_accuracy: 0.6443 - val_loss: 2.4986\n",
      "Epoch 39/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9486 - loss: 0.1465 - val_accuracy: 0.6220 - val_loss: 3.0726\n",
      "Epoch 40/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9456 - loss: 0.1459 - val_accuracy: 0.6423 - val_loss: 2.3598\n",
      "Epoch 41/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9471 - loss: 0.1442 - val_accuracy: 0.6463 - val_loss: 2.8219\n",
      "Epoch 42/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9574 - loss: 0.1143 - val_accuracy: 0.6402 - val_loss: 2.7714\n",
      "Epoch 43/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9546 - loss: 0.1331 - val_accuracy: 0.6321 - val_loss: 3.1096\n",
      "Epoch 44/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9511 - loss: 0.1276 - val_accuracy: 0.6423 - val_loss: 2.8021\n",
      "Epoch 45/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.9563 - loss: 0.1297 - val_accuracy: 0.6402 - val_loss: 2.6551\n",
      "Epoch 46/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9453 - loss: 0.1365 - val_accuracy: 0.6402 - val_loss: 2.8964\n",
      "Epoch 47/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.9583 - loss: 0.1084 - val_accuracy: 0.6463 - val_loss: 3.2512\n",
      "Epoch 48/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9610 - loss: 0.0977 - val_accuracy: 0.6524 - val_loss: 2.9224\n",
      "Epoch 49/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9667 - loss: 0.0861 - val_accuracy: 0.6565 - val_loss: 2.9583\n",
      "Epoch 50/50\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.9728 - loss: 0.0767 - val_accuracy: 0.6748 - val_loss: 2.6035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2998c2bb9d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    train_data, train_labels,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_data=(val_data, val_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!C:\\Users\\faisa\\AppData\\Roaming\\Python\\Python312\\Scripts\\streamlit.exe run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\cnn_tuning\\tuner0.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A total of 2 objects could not be loaded. Example error message for object <Dense name=dense_1, built=True>:\n\nThe shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(512, 512), Received: value.shape=(512, 6). Target variable: <KerasVariable shape=(512, 512), dtype=float32, path=sequential/dense_1/kernel>\n\nList of objects that could not be loaded:\n[<Dense name=dense_1, built=True>, <Dense name=dense_2, built=True>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 133\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Perform the hyperparameter search\u001b[39;00m\n\u001b[0;32m    128\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m    129\u001b[0m     train_data, train_labels,\n\u001b[0;32m    130\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m    131\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(val_data, val_labels)\n\u001b[0;32m    132\u001b[0m )\n\u001b[1;32m--> 133\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py:400\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:366\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py:331\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Reload best checkpoint.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Only load weights to avoid loading `custom_objects`.\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n\u001b[1;32m--> 331\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_checkpoint_fname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:295\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    293\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 2 objects could not be loaded. Example error message for object <Dense name=dense_1, built=True>:\n\nThe shape of the target variable and the shape of the target value in `variable.assign(value)` must match. variable.shape=(512, 512), Received: value.shape=(512, 6). Target variable: <KerasVariable shape=(512, 512), dtype=float32, path=sequential/dense_1/kernel>\n\nList of objects that could not be loaded:\n[<Dense name=dense_1, built=True>, <Dense name=dense_2, built=True>]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Parameters\n",
    "input_shape = (128, 128, 3)\n",
    "num_classes = 6\n",
    "\n",
    "# Paths\n",
    "base_path = './Classify'\n",
    "train_dir = os.path.join(base_path, 'train')\n",
    "test_dir = os.path.join(base_path, 'test')\n",
    "labels = ['backpain', 'chestpain', 'cough', 'falling_down', 'headache', 'neckpain']\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jpg\"):  # Make sure to process only images\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = load_img(img_path, target_size=(128, 128))\n",
    "            img_array = img_to_array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "def load_dataset(base_dir, labels):\n",
    "    data = []\n",
    "    label_list = []\n",
    "    for label in labels:\n",
    "        folder_path = os.path.join(base_dir, label)\n",
    "        if os.path.isdir(folder_path):\n",
    "            images, lbls = load_images_from_folder(folder_path, label)\n",
    "            data.extend(images)\n",
    "            label_list.extend(lbls)\n",
    "    data = np.array(data)\n",
    "    label_list = np.array(label_list)\n",
    "    return data, label_list\n",
    "\n",
    "# Load the datasets\n",
    "train_data, train_labels = load_dataset(train_dir, labels)\n",
    "test_data, test_labels = load_dataset(test_dir, labels)\n",
    "\n",
    "# Encode labels\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "train_labels = np.array([label_to_index[label] for label in train_labels])\n",
    "test_labels = np.array([label_to_index[label] for label in test_labels])\n",
    "\n",
    "# Normalize data\n",
    "train_data = train_data.astype('float32') / 255.0\n",
    "test_data = test_data.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical\n",
    "train_labels = to_categorical(train_labels, num_classes)\n",
    "test_labels = to_categorical(test_labels, num_classes)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(\n",
    "            filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=32),\n",
    "            kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n",
    "            activation='relu',\n",
    "            input_shape=self.input_shape\n",
    "        ))\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(\n",
    "            filters=hp.Int('conv_2_filter', min_value=32, max_value=128, step=32),\n",
    "            kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        model.add(tf.keras.layers.Conv2D(\n",
    "            filters=hp.Int('conv_3_filter', min_value=32, max_value=256, step=32),\n",
    "            kernel_size=hp.Choice('conv_3_kernel', values=[3, 5]),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('dense_units', min_value=128, max_value=512, step=32),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('dense_units', min_value=128, max_value=512, step=32),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(tf.keras.layers.Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n",
    "# Define the hypermodel\n",
    "hypermodel = CNNHyperModel(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "# Set up the tuner\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='cnn_tuning'\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(\n",
    "    train_data, train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(val_data, val_labels)\n",
    ")\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
